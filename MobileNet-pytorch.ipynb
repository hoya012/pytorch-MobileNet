{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils import data as D\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "validation_ratio = 0.1\n",
    "random_seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomCrop(224, padding=28),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_validation)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                          shuffle=True, num_workers=0)\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "initial_lr = 0.045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class depthwise_conv(nn.Module):\n",
    "    def __init__(self, nin, kernel_size, padding, bias=False, stride=1):\n",
    "        super(depthwise_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernel_size, stride=stride, padding=padding, groups=nin, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dw_block(nn.Module):\n",
    "    def __init__(self, nin, kernel_size, padding=1, bias=False, stride=1):\n",
    "        super(dw_block, self).__init__()\n",
    "        self.dw_block = nn.Sequential(\n",
    "            depthwise_conv(nin, kernel_size, padding, bias, stride),\n",
    "            nn.BatchNorm2d(nin),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.dw_block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class one_by_one_block(nn.Module):\n",
    "    def __init__(self, nin, nout, padding=1, bias=False, stride=1):\n",
    "        super(one_by_one_block, self).__init__()\n",
    "        self.one_by_one_block = nn.Sequential(\n",
    "            nn.Conv2d(nin, nout, kernel_size=1, stride=stride, padding=padding, bias=bias),\n",
    "            nn.BatchNorm2d(nout),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.one_by_one_block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, input_channel, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            dw_block(32, kernel_size=3),\n",
    "            one_by_one_block(32, 64),\n",
    "            \n",
    "            dw_block(64, kernel_size=3, stride=2),\n",
    "            one_by_one_block(64, 128),\n",
    "            \n",
    "            dw_block(128, kernel_size=3),\n",
    "            one_by_one_block(128, 128),\n",
    "            \n",
    "            dw_block(128, kernel_size=3, stride=2),\n",
    "            one_by_one_block(128, 256),\n",
    "            \n",
    "            dw_block(256, kernel_size=3),\n",
    "            one_by_one_block(256, 256),\n",
    "            \n",
    "            dw_block(256, kernel_size=3, stride=2),\n",
    "            one_by_one_block(256, 512),\n",
    "            \n",
    "            # 5 times \n",
    "            dw_block(512, kernel_size=3),\n",
    "            one_by_one_block(512, 512),\n",
    "            dw_block(512, kernel_size=3),\n",
    "            one_by_one_block(512, 512),\n",
    "            dw_block(512, kernel_size=3),\n",
    "            one_by_one_block(512, 512),\n",
    "            dw_block(512, kernel_size=3),\n",
    "            one_by_one_block(512, 512),\n",
    "            dw_block(512, kernel_size=3),\n",
    "            one_by_one_block(512, 512),\n",
    "            \n",
    "            dw_block(512, kernel_size=3, stride=2),\n",
    "            one_by_one_block(512, 1024),\n",
    "            \n",
    "            dw_block(1024, kernel_size=3, stride=2),\n",
    "            one_by_one_block(1024, 1024),\n",
    "        )\n",
    "                \n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        body_output = self.network(x)\n",
    "        \n",
    "        avg_pool_output = F.adaptive_avg_pool2d(body_output, (1, 1))\n",
    "        avg_pool_flat = avg_pool_output.view(avg_pool_output.size(0), -1)\n",
    "\n",
    "        output = self.linear(avg_pool_flat)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNet(3, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNet(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (4): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (8): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (9): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (10): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (11): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (12): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (13): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (14): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (15): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (16): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (17): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (18): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (19): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (20): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (21): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (22): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (23): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (24): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (25): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (26): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (27): dw_block(\n",
       "      (dw_block): Sequential(\n",
       "        (0): depthwise_conv(\n",
       "          (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024, bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (28): one_by_one_block(\n",
       "      (one_by_one_block): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 epoch] Accuracy of the network on the validation images: 60 %\n",
      "[1 epoch] Accuracy of the network on the validation images: 65 %\n",
      "[2 epoch] Accuracy of the network on the validation images: 71 %\n",
      "[3 epoch] Accuracy of the network on the validation images: 72 %\n",
      "[4 epoch] Accuracy of the network on the validation images: 78 %\n",
      "[5 epoch] Accuracy of the network on the validation images: 77 %\n",
      "[6 epoch] Accuracy of the network on the validation images: 79 %\n",
      "[7 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[8 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[9 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[10 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[11 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[12 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[13 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[14 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[15 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[16 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[17 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[18 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[19 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[20 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[21 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[22 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[23 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[24 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[25 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[26 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[27 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[28 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[29 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[30 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[31 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[32 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[33 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[34 epoch] Accuracy of the network on the validation images: 89 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-11111d035ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9)\n",
    "\n",
    "for epoch in range(100):  \n",
    "    if epoch == 0:\n",
    "        lr = initial_lr\n",
    "    elif epoch % 2 == 0 and epoch != 0:\n",
    "        lr *= 0.94\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \"\"\"\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        show_period = 250\n",
    "        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n",
    "            print('[%d, %5d] loss: %.7f' %\n",
    "                  (epoch + 1, i + 1, running_loss / show_period))\n",
    "            running_loss = 0.0\n",
    "        \"\"\"\n",
    "        \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
    "          (epoch, 100 * correct / total)\n",
    "         )\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship  ship plane  frog  frog   car  frog   cat   car plane truck   dog horse truck  ship   dog horse  ship  frog horse plane  deer truck   dog   cat  deer plane truck  frog  frog   dog  deer   dog truck   cat  deer   car truck   dog  deer  frog   dog  frog plane truck   cat truck horse  frog truck  ship   cat   cat  ship  ship horse   cat   dog  frog horse   dog  frog   cat\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# print images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(64)))\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "                \n",
    "        for i in range(labels.shape[0]):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pytorch_1.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
